✔ 누크를 이용한 color management 원리와 Aces 워크플로우 원리

카메라에서 부터 모니터까지 일관된 표준으로 부터 예술적 영상 작업을 이루어지게 한다 

**what is color management? 

색공간 변환을 통제하는 프로토콜로써 이미지 재현과 창작의도를 다양한 장치 및 모든 부서에서 공통된 시각에 맞추어 작업할 수 있도록 일관성있게 제공하는 "프레임 워크"
(모두가 어디서든 같은 이미지를 보게하는것) 

** 왜 필요한데? 

필름 카메라 시대로 

네거티브 필름으로 촬영 후 스캔을 뜬다 (cineon file) 이후 컴퓨터에 렌더나 선형이미지를 생성하고 포토샵이나 기타 소스에 다양한 디지털 이미지가 나왔다 >>일반적으로 모두 같은 RGB형식을 사용
scan > cgi > digital media  로그 감마 LIN 인코딩 컴퓨터로 처리 후 극장이나 방속국으로 전송 

디지털 시대의 등장 

우리는 작업 목표와 방식을 명확히 알아야 한다. 필름 시대에도 일맥상통하는 얘기지만 디지털 시대에 있어선 상황이 아주 복잡해졌기에 더욱 명확히 알 필요가 있다. 
미디어 산업에 있어 혁명을 일으킨 요소는 "디지털 카메라의 등장" 다양한 회사들은 각자의 방식으로 빛을 인코딩한다. (다양한 색역과 변환 함수) 

또한 우리가 콘텐츠를 보는 방식또한 다양해짐 아날로그 필름 영사 방식도 아직 존재하지만 SD, HD, UHD 등 다양한 버전 각 버전의 색공간이 상이 그리고 HDR TV와 프로젝터, 컴퓨터 모니터, 휴대폰
,테블릿 

![image](https://user-images.githubusercontent.com/90597861/135765676-d846aeb6-c905-47fd-8dd0-ccf90680dd6c.png)

다양한 업체들의 콘텐츠를 고품질 표준에 맞추어 디스플레이해야 하는 상황. 같은 작품을 다른 회사, 다른 시설에서 작업을 할 떄에도 색상은 아주 중요 

**이런 상황 속 발생하는 문제 

1. 이미지를 캡쳐하는 방식 

각 회사 마다 빛의 표현이 다르다. (Clog, Log3G10, SLog, SLog2, SLog3, RedLog, AlexaLog, sRGB, Rec709 등) 클립 각각의 색공간은 제조사가 구체적으로 설계한 것 (센서가 재현할 수 있는 컬러의 정확도를 
최적화 하기 위해) 이를 이해하기 위해 색공간에 대한 정확한 이해가 필요. 

**Color space 

색상모델에서 유래한 색 구성 성분을 조합한것 (범위를 수학으로 표현), 색상모델은 그 목적에 따라 다양하다. CIEXYZ(인간인지를 범주화_국제 조명위원회), CMY or CMYK(인쇄용 잉크), RYM (물감 예술 디자인)

우리가 주목할것은 HSV(색조와 채도,명도),HSL(색조와 채도,휘도) 따라서 빛의 삼원색인 RGB에 주목해야한다. 디스플레이나 카메라는 모두 RGB사용 왜냐면 이 머신들이 인간색각을 참조해서 만들어졌기 떄문.

*인간이 색을 보는 방법 

인간의 눈안에 3가지 감광세포가 존제 > 다양한 빛의 파장을 포착 그 파장을 가시 스펙트럼이라 칭함 

가시 스펙트럼을 색을 혼합해 연속된 파장으로 펼치면 1차원으로 볼 수 있다. (보라색은 없다. 보라는 단일 빛 파장에서는 볼 수 없기에 마젠타는 작은 원추 세포가 파랑을 감지하는 걸 포착할 떄 뇌에서 빨간 원추세포가 동시에 자극 받아야 한다. 중간 원추세포인 녹색이 자극받지 않은 상태로 그떄 마젠타가 뇌에 떠오른다. 만약 3개의 원추세포 모두가 자극 받으면 3색 자극이라 칭한다.) >> 우리는 그 모든 색이 표현될 수 있도록 배열해야함. 

![FG](https://user-images.githubusercontent.com/90597861/136048289-d6c69f58-57f4-4ed6-8973-8dc6431b3c85.JPG)

*가시 스펙트럼의 2차원화 (컬러 휠)

컬러 휠에는 앞서 언급했던 보라색이 존재한다. 원의 둘레는 최대새기에서의 색상 (HUE) 컬러휠은 휴와 채도를 나타낼 수 있다. 빛의 밝기나 세기를 고려하지 않았다. 이를 CHROMATICITY라 한다. 

![DFGDF](https://user-images.githubusercontent.com/90597861/136049276-3072d324-8e3b-425c-923c-b61a5062a0f5.JPG)

문제는 우리가 모든 색을 동일하게 인지하지 않는다. "특정 파장을 더 예민하게 반응" >색상의 휘도에 직접적인 영향을 미친다.  

(x,y)축을 사용한 좌표의 조합을 튜플이라한다. "y축은 두가지 용도로 쓰인다. 하나는 x축 좌효와 짝을 지어 도표의 한 지점을 지정, 다른 하나는 표본의 "휘도"를 나타냄 그래서 특정 색공간에서 휘도 성분을 대문자 Y로 표현했구나 

가시 스펙트럼에서 빛의 파장을 수용하기 위해 색상을 공간안에(TUPLE) 구성하면 "SPECTRAL LOCUS by CIE1931" 

![SDFDS](https://user-images.githubusercontent.com/90597861/136051974-e49b112b-f5d4-44dd-acab-145ae90603c4.JPG)

컬러휠 내에 파장은 없지만 색상이 존재했던 것처럼 (보라) 다이어그램에서 밑바닥 라인을 "LINE OF PUPPLE" 이라 칭 색상은 있지만 파장은 없다. 

또 스펙트럼 가장자리의 색조로 갈 수록 채도와 비슷한 개념으로 "순도"라 한다. 이는 단일 파장이 지배적이라는 것을 뜻한다 그런데 마젠타 방향으로는 순도가 존재하지 않는다. 파장이 없으니까 하지만 채도는 존재한다. 

이 CIE 다이어그램은 그냥 색공간이 아닌 "COLOR GAMUT OF HUMAN VISION"을 나타낸다. 다시말하면 우리가 볼 수 있는 색을 칭함. 저 안에 없는 표본(x,y)는 개멋 외부에 있지만 수학적으로는 존재하는것 색역을 학습하는데 있어 스펙트럽 궤적 외부의 값을 이해해야하기 떄문에 이 개념은 중요 

*gamut이 뭔데? 

정의된 부분이 의미하는 전체부분을 칭함. 우리의 경우엔 색상이 됨. 정의 된 특정 범위 내의 모든 색상을 말함

![DSFSFDG](https://user-images.githubusercontent.com/90597861/136055591-77b17c30-a6f6-4b1e-b4a8-52f27e4ebf5b.JPG)

2차원으로 무한한 영역의 공간에서 특정 공간을 기준으로 잡고 (사진의 정사각형) 중심점을 기준으로 3점을 이어 삼각형의 특정 공간을 만든다. 이 삼각형이 GAMUT이 된다. 

이를 COLOR  GAMUT 에 적용하면 "특정 장치가 포착하거나 재생하는 색상의 양을 다이아그램위에 GAMUT으로 나타낼 수 있는것. 즉 보통 CIE 스펙트럼을 기준으로 3개의 점과 중심점(WHITE POINT)으로 특정 COLOR GAMUT을 나타낸다.  

![DASGFDEGF](https://user-images.githubusercontent.com/90597861/136057674-2fafca4b-1ed3-4c62-a281-74a49c2876da.JPG)

기준 컬러게멋은 상대적 개멋(평균 인간 시각에 대해 상대적), 타겟 컬러 게멋은 절대적 개멋 (튜플에서 수학적인 값으로 배정된 것이니까)  

따라서 COLOR GAMUT은 

채도라고 불러왔던 색상의 강도를 나타낸다. 색상이 재현하는 범위의 한계를 설정한다. 모니터나 프로젝터같은 디스플레이 OUTPUT DEVICE의 잠재적인 채도 구현 능력, 카메라 같은 INOUT DEVICE의 채도 처리 능력을 일컫는다. 


*온도와 마젠타를 이용해서 색을 살펴보기 

다이아그  램의 중심점은 "최저 채도점(WHITE POINT)"다. > 모든 색상은 최고 강도에서 나타난다. 그게 흰색의 양상을 나타낸다.(흰색은 최저 채도이다?) 하지만 중심은 불분명하다. 

![sdfrgdhg](https://user-images.githubusercontent.com/90597861/136063658-2656c63a-c422-48b5-8657-c58afe3076a8.JPG)

따라서 일반적으로 중심은 색상값의 특정 범위 내에서 산출된다. PLACKIAN LOCUS (흑체궤적)는 온도에 따라 변하는 흑체의 색도에 따라 궤적을 나타낸 것    

![RFEDGDFG](https://user-images.githubusercontent.com/90597861/136231974-8bdcef0b-e9f7-4fd8-b080-446c2e786039.JPG)

오른쪽으로 갈 수록 낮은 온도의 붉은색, 왼쪽으로 갈 수록 높은 온도의 파란색이 된다 (즉 이 흑체 궤적은 색온도를 나타냄) 

등온선

![ghfsdsds](https://user-images.githubusercontent.com/90597861/136232958-b0469ad8-35d9-4225-9904-1532e4160e3b.JPG)

표본의 같은 색온도를 유지하면서 색의 변화하는 방향을 나타냄 

즉 마젠타와 색온도로 색을 나타낼 수 있음  누크에선 온도와 마젠타에 사용할 색상 조절기가 있다. 두 슬라이더를 따로 조정하여 한 슬라이더를 움직이는 동시에 다른 성분은 유지하게 한다. 
우리의 눈은 주변 환경을 유지하기 위해 들어오는 빛의 온도를 균형있게 유지함 따라서 이 색온도에 익숙하다. 

이 화이트 포인트는 CIE에 의해 표준화 됨. 우리가 여러 조명 상황에서 감지하는 백색을 나타내는 것 (WHITE BALANCE) EX) CIE STANDARD ILLUMINANT D65 (6500k=주광DAYLIGHT) 

**다시 COLOR SPACE로 돌아와서 

카메라와 디스플레이는 인간의 눈과 비슷한 방식으로 이미지를 재생. 워추세포가 인지하는 빛의 파장 RGB 3색 자극신호에 근거한 처리 방식. 따라서 이 3색은 3개의 구성 성분이고 이 3색을 조합해서 공간 내 모든 색을 정의한다. 

스펙트럼 내의 3개의 꼭지점은 색을 발생하는 신호인 우리가 원색이라고 하는 색상을 구현. ( 꼭지점으로 부터 가장 멀리 떨어져 있다) 그 꼭지점을 이으면 바로 개멋이 됨 (컬러 스페이스)
개멋이 넓을 수 록 많은 색을 표현 할 수 있다. 개멋이 정해졌으면 가장 채도가 없는 부분인 WHITE POINT를 지정한다. "백색광이 나타나는 곳" 

![LJKHJGH](https://user-images.githubusercontent.com/90597861/136238422-ea22c427-ee93-4d47-b947-9fb781a060df.JPG)  sRGB 색공간 

>> 아 그니까 우리가 화이트 밸런스를 하는것은 프레임 내에서 가장 백색으로 나타나야 할 부분을 백색으로 맞춰주는 과정을 말하는 거구나. 그래서 색온도와 마젠타 슬라이드를 조절하는 거구. 

![KGYFTDRSEAS](https://user-images.githubusercontent.com/90597861/136241007-dfc0e46f-50da-48a1-9c81-b2e74e044136.JPG)

sRGB의 중앙이 정확히 앞서 나왔던 D65가 된다. 이것이 현재 세계 대부분의 컴퓨터가 지배적으로 사용하는 색공간. 그래서 이 색공간이 산업의 표준이다. HP와 마이크로소프르사에서 개발 되었는데 모니터와 프린터와 웹에서도 사용. VFX 산업표준으로 사용 됨. 누크도 오랜 기간동안 sRGB를 표준으로 사용해왔다. 하지만 상황은 변했다. 우리는 이제 개멋이 삼원색에 근거한 화이트 포인트로 형성 된다는 것을 안다. 

*색공간을 구성하는 마지막 요소 TRANSFER FUNCTION(전달함수) F(X)

이미지 캡쳐 장치의 선형 3색 자극값과 비선형 전자 신호값의 매핑값(지도화)을 의미. 

카메라와 같은 입력 장치가 담는 모든 빛의 표본과 노출도 색공간 내 정확한 위치에 배분 가능 "함수를 통해서". 센서 제조사들은 구체적인 함수를 생성해 센서모델이 영상자료 기록 성능을 높여 카메라의 전체 색상 재현 성능을 최적화. 즉, 센서나 디스플레이가 색상 데이터를 색공간 내에 정확한 위치에 배치하는 방식.    

![FDHGFGHJGHG](https://user-images.githubusercontent.com/90597861/136256794-46d4a3f2-db13-4c79-ae79-bfee341ba947.JPG)

포착장치에 사용하는 전달함수는 "입력전달함수" 목표 디스플레이의 이미지 값을 전환하도록 설계하는 "출력전달함수" 같은 과정을 반대로

![KLJHGFDFD](https://user-images.githubusercontent.com/90597861/136258755-a64d47d9-df46-40a5-9a88-ad6d91bb5a99.JPG)

각 색상모델의 모든 3원색 성분을 나타내는 함수의 결과의 자취를 CHARACTERISTIC CURVE라 칭함 > 이것은 카메라가 빛을 포착하는 기능과 성능을 정의. 디지털 카메라나 다른 입력장치들의 특성을 나타내는것. 

우리가 설정한 데이터에 대응하는 수학적 작업에 따라 전달함수는 여러 카테고리로 나뉜다. 

1.LINEAR (LIN) 인풋과 아웃풋이 동일. 신호가 변형되지 않았다는 뜻 (RAW). 컴퓨터는 이미지를 선형으로 생성한다. 
2.LOGARITHMIC (LOG) 카메라와 필름 스캐너에 사용. 다양한 노출에 따른 빛의 민감도와 세밀한 감지력 빛의 움직임을 정확하게. 처음에 필름스캔용도로 개발 알렉사 로그C가 이 유형에 속한다.
3.GAMMA CRT모니터 교정용으로 개발되었다가 다른 디스플레이용으로 진화. 곡선의 종점을 그대로 유지한다. 하지만 그 사이 나머지 값은 리매핑한다. 예로는 컴퓨터 모니터 용인 sRGB나 HDTV용 REC.709 이들은 SDR에 속한다. 
4.HYBRID LOG GAMMA(HLG) 로그와 곡선 내 감마 함수를 합친 것 PERCEPTUAL QUANTIZAR (PQ) HDR 휘도 신호를 최대 10,000니트 까지 허용. 이 두 함수는 HDR에 소속되어 있으며 현대의 디스플레이에 SDR 모니터 보다 더 밝은 값의 신호를 나타낼 수 있게 한 것.  

![캡처](https://user-images.githubusercontent.com/90597861/141178468-cd883d41-ee44-4ba2-b294-d56952a24f37.JPG)

*look up table (LUT) 

룩업테이블은 엄연히 전달함수의 개념과 구분될 필요가 있다. 룩업테이블은 처음부터 색상처리과정의 일부. 특히 특정 색공간을 목표 디스플레이에서 시각화 되도록 색공간을 전환할떄 유용.

룩업테이블이란? 대응점으로 구성된 데이터의 단순배열. 주어진 값, 혹은 입력값으로 요구하는 목푯값이나 출력값으로 전환하라는 하나의 지시목록 (각각의 단일화소에 적용). 컬러로 따지면 입력 색상값을 출력 색상값으로 변환하는것 = 리매핑작업 

LUT는 함수결과나 배열에 저장된 임시값으로 배열을 사전산출 할 수 있다. 따라서 전달함수란 특정 유형의 LUT라고 볼 수 있다. 하지만 모든 LUT가 전달함수를 의미하는것은 아님. 어떤 LUT는 색공간을 변환한다는 의미이고 어떤 LUT는 단순히 크리에이티브 룩을 적용.

*다음 사전 산출된 LUT와 원래 함수를 보자. 

1D LUT (RGB 3개의 성분을 하나의 함수로 표현) 가장 어두운 0부터 가장 밝은 1까지 모든 채널의 성분을 나타낸다. 10bit대신 쓰는격. x는 입력값, y는 출력값(결과값)

기억해야할건 입력값의 최댓값은 최대 비트심도가 허용하는 값을 넘으면 안됨 예를들어 10bit에서 10bit 1025라는 값은 없는것. 하지만 출력값은 정규값 1이상의 값을 가질 수 있다.

RAW 파일의 경우 선형으로 입력값이 출력값 그대로 나온다. 주어진 키값으로 선형배열을 통해 함수를 구한다. 다시말해 이미지가 변하지 않는다.

![SDFGF](https://user-images.githubusercontent.com/90597861/141189511-b2c775e3-4c06-4c47-b1f0-89aa50aa7f18.JPG)

LUT의 정밀도는 함수의 키 개수에 좌우된다. (8bit의 경우 256개의 키가 있다. 따라서 사전산출된 모든 잠재값을 구한다, 반면 동일한 LUT를 10bit 이미지에 적용하면 1024의 값이 나오고 그의 1/4 값만 사전 산출한다. 나머지는 선형보간으로. 이게 배열 (array). 한편 이미지 비트에 상관없이 함수를 구해 이미지에 적용하는 경우가 있다. 

f(x)=x 사전 산출된 배열을 정의한 것이라고 보면 됨. 

다음 함수에서 최대 입력값인 1을 넣으면 1.5가 나오는데 이 값은 데이터는 살아있으나 모니터로는 볼 수 없다 (1의 값으로 보게 됨). 

![dsfs](https://user-images.githubusercontent.com/90597861/141192579-f1b27518-77d2-4b9b-a4f0-461a2a352ee9.JPG)

다음 배열을 보자. 

키값을 이용해 선형보간을 하면 우리의 선이 끊어 진듯하다. 

![dsfgth](https://user-images.githubusercontent.com/90597861/141193611-8e20a58b-9036-4434-a0de-f38d4d39d44e.JPG)

이 선혀보간이 제대로 작동하지 않는 이유는 키의 값이 모자르기 때문이다.(데이터가 부족) 그럼 미리 산출된 렅을 쓰는 대신 저 세지점이 생성한 함수를 구해보자. 직선이 아닌 곡선이 형성된다. 

이게 Log 함수 f(x)= x

![yhfgjgfh](https://user-images.githubusercontent.com/90597861/141193985-9219d60f-75c4-458d-a216-1d2332693584.JPG)

3D LUT의 경우엔 더 방대한 작업이 필요하다 (각각의 RGB채널에 함수(배열)을 구해야 한다.)

LUT는 모든 원색 변환을 적용해서 크리에이티브 룩을 나타내는데에 사용가능. 기본 색 변환이란 모든 화소를 보정한다는 의미. 따라서 LUT는 모든 이미지 화소에 지정값을 리매핑하는 고정색 변환. 

*색상변환 오디세이 

태초에 필름카메라로 필름에 영상을 찍었다. 이후 네거티브 필름을 포지티브로 변환하고 극장에서 영사기로 상영. (아날로그식 물리적 자원) 하지만 필름을 TV로 보려면 물리적 장치를 전자신호로 변환이 필요. 그래서 텔레시네(비디오 카메라)를 이용해 네거티브 필름을 테이프에 저장. (여전히 아날로그) 이후 개인 컴퓨터의 보급으로 CRT모니터가 나왔다. (이떄 TV와 PC의 영상 재현 능력은 비슷) 어떤 이미지를 보여주려 하더라도 소프트웨어를 통한 보정이 필요. 이떄 모든 CRT 모니터는 색표준이 없었다. 또한 각각의 소프트웨어들은 고유의 색상을 구현했다. 이후 컴퓨터와 모니터는 새롭게 구축된 sRGB를 따르게 돼었다. 모니터와 소프트웨어가 같은 색공간을 쓰기 시작했기 때문에 우리는 제대로 된 색을 볼 수 있게됨. 이후 필름 스캐너가 개발 되고 디지털 색보정이 탄생됐다. DI라는 과정으로 원본 네거티브 필름을 스캔해서 10bit 시네온 파일 시퀀스로 변환한다. 그런데 또 상영할땐 다시 영사 슬라이드로 (아날로그) 바꿔서 출력; 하지만 디지털 영사기가 발명됨. 아바타로 인해 큰 각광을 받기 시작. 디지털 시네마는 필름 롤을 들고 다닐 필요가 없어졋기에 큰 각광을 받음. 하지만 제대로 디지털화가 된건 바로 디지털 카메라의 발명 이후다. 더이상 네거티브 필름을 스캔할 필요가 없어짐. 이때 기존의 워크플로우를 유지하기 위해 디지털 카메라 데이터를 여전히 cineon 파일 시퀀스로 변환했다. 이후 TV는 CRT에서 LCD로 바뀐다 (디지털화 되었다) 디지털화 중간 시기엔 CRT가 이미지를 재생할 때와 동일한 결점을 가진 소프트웨어를 장착했다. 따라서 여전히 모두가 예전 시스템이 재현하는 교정된 신호로 봤다. LCD 자체의 문제가 아닌 호환의 문제. 기존의 데이터들을 봐야했기 떄문에. TV가 디지털화 돼었다는건 내부에 컴퓨터가 내장되었다는것. 따라서 컴퓨터의 발전과 같이한다. SD화질이나 NTSC, PAL 시대 이후 세계공통의 HD(720p, 1080p)의 시대가 열림. 둘다 같은 색공간을 사용. rec.709 그 이후 4k HDR TV가 나온다. 이제 대형 스크린과 휴대폰, 테블릿의 대결구도 하에 DI는 훨씬 복잡해 진다. 매우 각기의 다른 소스들을 같은 sRGB 모니터로 보게끔 해야한다. 근데 그걸 컴퓨터 성능이 있는 모니터와 더 좋은 스크린에도 전달되어야 하는 상황이 도래. 그럼 시각화 되지 않는 다이나믹 레인지를 어떻게 작업해야 할까? 이때 LUT를 사용해서 서로 다른 장치로 변환한다. 

![FGDHFDG](https://user-images.githubusercontent.com/90597861/141199006-81250685-8d57-4a0e-9316-4c0a062b3d7d.JPG)

LUT는 이미지가 생성되는 장소와 그걸 어디로 전송할지에 달린 것. 또 나중에 더 좋은 디스플레이가 나오면 기존에 데이터들은 어떡할건데? 이 문제는 한 문제가 좌지우지한다. 특정 스크린에 맞게 콘텐츠를 채택해서 보정하는건 모든 디스플레이에 적합하도록 실제 이미지 데이터를 바꾸는거다. 따라서 우리는 새로운 디스플레이가 나오면 기존의 데이터를 그에 맞게 변환해야 하는것. 이게 Display Referred workflow 

하지만 다른 방법도 있다 

*Scene Referred Workflow 

일단 마스터 색공간(통합 색공간)을 택한다. 우리가 주입할 파일의 모든 작업 범위를 포함하는 넓은 영역을 택해야 한다. (HDR 호환성을 갖추는건 필수) 이는 어떤 디스플레이건 상관없다. 단지 데이터의 수학적 보관용기. 이제 소스들을 불러오자면 INPUT TRANSFORM을 통해 로우 데이터를 변환하거나 각 장치에서 나온 소스자료를 통합 색공간에 넣는다. 렌더링한 CGI(컴퓨터 화상처리. 보통 컴퓨터를 사용하는 모든 회화적 작업을 말한다)를 바로 인코딩해서 통합 색공간으로 넣기 때문에 색공간을 변환할 필요가 없다. 전통적인 sRGB 선형으로 미리 랜더를 한 경우 언제든지 통합 색공간을 바꿀 수 있다. 이러면 이제 각기의 다른 소스들이 모두 같은 색공간에 있다. 따라서 같은 개멋, 화이트 포인트, 같은 전달함수를 쓴다. 같은 색공간에 있지만 여러 장치에서 나온 소스들은 색공간을 다 쓰는것도 있고 아닌것도 있다. 예를 들어 아이폰에서 나온 소스는 그 영상을 찍은 마스터 색공간에 따라 더 작은 영역을 할당할 것이다. 따라서 넓은 색공간(통합된)에 넣었다고해서 화질이 개선되는건 아님. 하지만손실도 없어. 우리가 누크에서 작업을 할떄에도 마찬가지. 누크에서 사용한 모든 소스들은 원본과 상관없이 32bit로 고정된다. 따라서 각기 다른 비트의 소스들을 섞을 수 있는것. 아이폰으로 찍든 아리 알렉사로 찍던 소스의 성능에 따라 색변환률이 달라지지만 색상 조정의 관점에서 같아진다는 것. >>우리 마스터 영상에 모든 데이터와 표현의도를 같이 온전히 담을 수 있고 그 영상이 다른 부서로 넘어갈 때 모든 사람이 스크린에서 보는 것과 동일한 색공간에 있는 영상이 모두 일치한다는 점에서 연속된 크리에이티브 룩을 유지할 수 있다. vfx 부서에 있어선 누크의 영상을 모니터나 영사기, TV에 따라 적절한 디스플레이 변환으로 시청자에게 적용할 수 있다. 영화 제작자가 원하는 룩을 시청자에게 보여줄 수 있지만 영상은 온전히 그대로 있는격. VFX 작업이 끝나면 모든건 DI로 넘어간다. 표현의도에 따라 최종 색보정이 이루어 지고 모든 최종 디스플레이에 맞춰 각각의 고유한 색공간에 따라 디스플레이 변환을 한다. 이때 임의로 더 작은 색공간으로 변환시에는 그에 맞는 색보정이 살짝 필요하다. 이제 기록을 보관하자면, 
통합 색공간에 있는 마스터 원본을 수거하고 보정과정은 색변환으로 저장될 것이다. 그래야 미래에 등장할 디스플레이에 맞춰 언제든 변환이 가능하니까. 이 과정은 미래를 대비하는 플로우로 색변환은 처음에 한번 마지막에 한번씩만 했다. 

![ASDGDF](https://user-images.githubusercontent.com/90597861/141205651-7caf4b6b-4eb4-4155-820d-6febb92f8078.JPG)

Display Referred vs Scene Referred Workflow 

전자는 디스플레이에 따른 색상 변형을 한다. 즉 디스플레이를 참조한다. 

후자는 색상 변형을 푸티지를 참조한다. 모든 디스플레이에 적용할 수 있다. 

전자는 각기 다른 장치들마다 디스플레이에 따른 LUT변환을 해야한다. 하지만 후자는 각기의 소스들을 통홥된 색공간에 넣어 보관하고 디스플레이에 따라 변환한다. 이는 일관된 연출의도에 따른 크리에이티브룩을 훼손할 가능성이 낮아진다. 

![SDGSDGSDFG](https://user-images.githubusercontent.com/90597861/141206266-61ab563a-e83f-4579-a199-4d153063e014.JPG)

✔ Gamma 곡선? 

 러트의 한 종류로 전달함수로 말할 수 있는건가 그럼. 우리가 보통 감마는 중간밝기의 보정값을 의미함, 그래서 흔히 감마 보정값이라고 칭함. 그래서 감마라하면 화면의 밝기 값을 조정한다고 생각해. (CRT 모니터 시대에 실제 이미지보다 어둡게 표현되는 오류. 그로 인해 감마곡선으로 밝게 저장하여 실제 이미지로 볼 수 있게 하기위해 탄생.) 
 
 호환성으로 인해 sRGB같은 경우에도 감마 2.2 커브로 표현되기 때문에 (sRGB 모니터 같은 경우에 감마2.2커브도 포함되어 있다는 말) JPG나 PNG 같은 경우에도 밝게 저장된다. 자동으로 감마 코렉션이 이루어 지는것. 
 
 ![SADGSADF](https://user-images.githubusercontent.com/90597861/141318676-df3dbc89-6688-4858-83e1-042cfa026aab.JPG)
 
 다시정리. 
 
Gamma curve ? 

입력신호 레벨과 출력신호 레벨의 관계을 표시 

*입출력 프로세스 

![dsfsfg](https://user-images.githubusercontent.com/90597861/141652116-bf1a4077-decc-4322-b7cd-80ccd97d58c2.JPG)

카메라는 피사체의 밝기 신호를 전자적인 신호로 바꾸고 디스플레이로 신호를 보낸다. 디스플레이로 보내진 그 전자 신호는 밝기 신호로 변환되며 이미지로써 피사체를 나타낸다. 우리가 알고있는 센서는 밝기만 판독을 한다. (컬러는 그 위로 필터를 씌우는 개념) 센서는 밝기 신호를 숫자(전자적인 신호)로 바꾸어서 모니터 쪽으로 전송을 하면 모니터는 그 숫자에 따라 전구를 킨다. 이때 전구는 각각 RGB로 나뉘어져서 자신에게 입력된 숫자대로 불의 세기를 결정한다. 

![DFASDASD](https://user-images.githubusercontent.com/90597861/141653811-f5d7687d-8fa8-43a1-b40e-2298fcc60a5e.JPG)

그런데 이때 피사체를 비디오 이미지에서 충실하게 나타내려면 출력신호는 입력신호와 완전한 비례를 이루어야한다 (리니어) 

![GSDFF](https://user-images.githubusercontent.com/90597861/141653924-964b142d-a8e1-4c62-9d86-f90b8b66de08.JPG)

이 그래프를 이해하려면 커브가 무엇인지 부터 이해할 필요가 있음. \

![dsfgsdfgsd](https://user-images.githubusercontent.com/90597861/141672529-ea771ee0-63cb-42b3-9863-cac01bbabe28.JPG)

그래프에서 커브가 45도를 유지할때 우리는 y=x라는 함수를 얻을 수 있다. 이는 리니어형태를 나타내며 입출력값이 같아진다. 우리는 피사체를 비디오 이미지에 충실하게 나타내려 이 리니어를 유지해야 한다. 출처 https://www.youtube.com/watch?v=s6sUrc6-ZoQ 

감마 커브의 유래는 crt 모니터에서 시작된다. 이는 위에서 충분히 설명했으므로 이하설명 생략. 어찌되었건 지금 LCD나 LED 모니터는 감마 2.2 커브를 유지할 필요가 없지만 규격에 따른 호환성을 위해 계속 흉내를 내는중. 

이런 감마 코렉션을 알기 전에 우리는 "베버의 법칙"에 대해 알아봐야한다. 

베버의 법칙이란 인간은 자극이 없는 상황에서의 추가된 자극은 민감하게 느끼면서 이미 많은 자극 속에서 추가되는 자극은 둔하게 느낀다. 예를들어 캄캄한 방에서 불하나를 키면 눈은 시각적 충격을 받는다. 하지만 밝은 방안에서 불하나 킨다고해서 별다르게 느끼지 않는다. 

![dsfgsdf](https://user-images.githubusercontent.com/90597861/141674415-ce87994c-2962-4ab5-ae93-de2262e51aa3.JPG)

이 그라데이션에서 인간의 눈은 1번이 정상적으로 보이지만 사실 2번이 정상적인 그라데이션이다. 인간은 베버의 법칙으로 인해 어두운 부분에서 더 민감하게 자극되기 때문에 1번이 더 고른 그라데이션이라고 느낌. 중간부분과 밝은 부분의 그라데이션을 잘 느끼지 못함. 그래서 2번이 더 밝게 느껴지는것. 

![sdfsdf](https://user-images.githubusercontent.com/90597861/141674518-355cc26e-60a8-46e3-afe4-ca55d9b703d8.JPG)

실제로 진정한 그레이는 2번이 맞음. 그래서 모니터는 인간의 눈에 맞게 어두운 부분의 밀도를 올리기로함. 그게 감마2.2 커브. 즉 감마 2.2 커브로 전체적으로 어둡게하여 인간의 눈에 더 자연스러운 그라데이션으로 만듬. 우리가 그간 사진이나 영상이 어두워 진걸 못느낀건 하드디스크에 저장할때 모니터 감마 커브에 맞추어 역으로 밝게 저장하기 때문이다. 그래서 모니터 규격인 sRGB나 TV규격인 REC709모두 감마 2.2커브를 역으로한 감마커브가 내제되어있음. 

![SDFSDHBDF](https://user-images.githubusercontent.com/90597861/141675728-fb66c35b-77de-414b-befe-7f692f3d4b3b.JPG)

근데 다시 리니어로 만들건데 뭣하러 그렇게함?? 하지만 여전히 데이터 상에서 어두운 부분의 디테일이 뭉쳐있다. 

*ACES 색영역을 쓰는 이유는 

위에서 ACES 워크플로우의 원리에 대해서 배웠다. 쉽게 말해 우리가 제작 과정에 있어서 넓은 개멋의 색공간을 쓰고 각 디스플레이에 맞게 색공간을 맞추어 송출하자는 것. 디스플레이가 가진 특성으로 인해 모든 디스플레이가 넓은 색공간을 가질 수는 없다. 

![DFSDFSDD](https://user-images.githubusercontent.com/90597861/141676591-2c3f84e3-585f-447b-92a0-04ebc97898a6.JPG)

*premult 방식의 이해 

RGBA에서 A는 알파값, 즉 투명도를 말하는데 프로그램에서 투명도를 어떻게 표현하는지를 그 방식을 말한다. 
프리멀트를 포토샵으로 따지면 마스킹을 씌어서 투명도를 작업하는걸 생각해보면 됨. 그러면 마스크 데이터가 포토샵을 껏다 켜도 여전히 남아있음. 즉 우리가 임의로 포토샵에 알파채널 같은걸 만들어 주는거임.( 포토샵은 기본적으로 스트레이트 방식이다. 직관적으로 지우면 지우고 다시 그리면 그리는.)

![FSDGSDF](https://user-images.githubusercontent.com/90597861/141683144-7030961e-f41b-45ff-acb7-dbe5bae50728.JPG)

우리가 원래 가진 파일의 픽셀에 마스크(알파)를 곱하는 것. 

각 픽셀이 가진 RGB에따른 데이터값. (r.g.b) 에 알파값을 곱한다면 0을 곱하면 0이 나올테고(투명) 1을 곱한다면 그대로 값이 나올것임(불투명). 0.5를 곱하면 반투명이 될거고. 이게 프리멀트 방식.

*누크에선??

누크에선 이 프리멀트 작업을 할 수도 안할 수 도 했다가 다시 풀수도 있다. 

![fsdghhghj](https://user-images.githubusercontent.com/90597861/141683320-8dc35647-8cf1-4f06-9759-5ec9534a69dc.JPG)

이런식으로 로토로 쉐입을 만들어 알파채널을 형성하고. 원본 파일에 프리멀트(곱하기)를 하줘야 제대로 된 작업물이 나온다. 만약 프리멀트를 하지 않을 경우는 위 사진 같은 결과물. 

![dtghdhj](https://user-images.githubusercontent.com/90597861/141683361-e6c74bc3-57fc-46cc-940f-a74a9b5fc5d3.JPG)

프리멀트를 한다면 제대로 나온다. 항상 알파값은 1일때 불투명하고 (흰색) 0일때 투명하다 (검정) 
